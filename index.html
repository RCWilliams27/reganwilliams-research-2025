<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Home | Spectral Graph Theory & Quantum Mechanics</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      background-color: #f8f9fa;
    }
    header {
      background-color: #343a40;
      color: white;
      padding: 1em;
      text-align: center;
    }
    nav {
      background-color: #495057;
      display: flex;
      justify-content: center;
      padding: 0.5em 0;
    }
    nav a {
      color: white;
      margin: 0 1em;
      text-decoration: none;
      font-weight: bold;
    }
    nav a:hover {
      text-decoration: underline;
    }
    main {
      max-width: 900px;
      margin: auto;
      padding: 2em;
    }
    section, .box {
      margin-bottom: 2em;
    }
    .box {
      background-color: #ffffff;
      border: 1px solid #dee2e6;
      padding: 1.5em;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    h2, h3 {
      color: #333;
      margin-top: 0;
    }
    /* Center formulas */
    .formula {
      text-align: center;
      font-family: Arial, sans-serif; /* consistent font */
      font-weight: bold;
      font-size: 1.1em;
      margin: 1em 0;
    }
    footer {
      background-color: #343a40;
      color: white;
      text-align: center;
      padding: 1em 0;
    }
  </style>
</head>
<body>
  <header>
    <h1>Spectral Graph Theory and Quantum Mechanics</h1>
  </header>

  <nav>
    <a href="index.html">Home</a>
    <a href="visualizations.html">Visualizations</a>
    <a href="meet.html">Meet Us</a>
  </nav>

  <main>
    <section>
      <h2>Project Overview</h2>
      <p>This research project explores the intersection of spectral graph theory and quantum mechanics. We focus on computing various types of graph entropy to understand their significance in both mathematical and physical contexts. Our goal is to model entropy through graphs by directly calculating it and examining how operations like rewiring and gluing affect its behavior. This site presents theoretical concepts, visualizations, and daily notes from our research process.</p>
    </section>

    <section class="notes">
      <h2>Daily Notes</h2>
    </section>

    <section>
      <h2>Entropy & Graphs</h2>

      <div class="box">
        <h3>What Is Entropy?</h3>
        <p>Entropy measures uncertainty or disorder in a system. More specifically, entropy reflects the number of different microscopic configurations (microstates) that correspond to the same observable condition (macrostate). Because there are naturally many more disordered configurations than ordered ones, systems evolve from low-entropy (more ordered) states to high-entropy (less ordered) states.</p>
      </div>

      <div class="box">
        <h3>Why Is It Important?</h3>
        <p>Entropy shows up across many fields of science, helping us understand everything from heat to information to the structure of the universe. There are several main types of entropy:</p>
        <ul>
          <li>Boltzmann Entropy</li>
          <li>Gibbs Entropy</li>
          <li>Shannon Entropy</li>
          <li>Von Neumann Entropy</li>
          <li>Bekenstein-Hawking Entropy</li>
        </ul>
      </div>

      <div class="box">
        <h3>Why Graphs?</h3>
        <p>Many real-world systems, such as epidemics, social networks, the internet, and key physical processes, involve entropy. Measuring this entropy helps us understand and predict their behavior. However, these systems are too complex to model using continuous equations alone. By discretizing these problems and applying linear algebra, we can study them more effectively. Graph theory provides a natural framework: we represent complex systems as networks of vertices and edges, studied via matrices. These matrices capture structural features closely tied to entropy. This graph-based, linear algebra approach forms the foundation of our research into the entropy of networks.</p>
      </div>

      <section>
        <h2>Von Neumann Entropy</h2>

        <div class="box">
          <h3>Our Focus</h3>
          <p>In this project, we use the spectrum of a graph’s Laplacian matrix to calculate von Neumann entropy. We then explore how it reflects a network's structural complexity and disorder. This led us to ask several questions:</p>
          <ul>
            <li>How does the entropy of well‑known graphs compare, and how are these differences reflected in their structure?</li>
            <li>Can we break a large graph into parts, calculate entropy for each, and then "glue" the pieces back together to calculate a total entropy value?</li>
            <li>How does entropy change when we rewire a graph’s connections?</li>
          </ul>
        </div>

        <div class="box">
          <h3>What Is Von Neumann Entropy?</h3>
          <p>Von Neumann entropy measures how complex or disordered a graph is by analyzing its structure.</p>

          <p>How We Calculate It:</p>
          
          <p>Degree matrix (D): This matrix shows how many connections each vertex has. Each diagonal entry tells you the number of edges connected to that vertex.</p>
          
          <p>Adjacency matrix (A): This matrix shows which vertices are connected. If two vertices share an edge, the matrix entry is 1; if not, it’s 0.</p>
          
          <p>The Laplacian matrix (∆): This matrix combines the above information by subtracting the adjacency matrix from the degree matrix, helping us analyze the structure and properties of the graph.</p>
          
          <p class="formula">∆ = D − A</p>
          
          <p>We then analyze the eigenvalues (λ) of the Laplacian to compute the von Neumann entropy using the formula:</p>
          
          <p class="formula">S = − ∑ λ ln λ</p>
        </div>

        <div class="box">
          <h3>Key Takeaways</h3>
          <ul>
            <li>Entropy measures uncertainty or disorder in a system.</li>
            <li>Different types of entropy connect ideas from thermodynamics, quantum mechanics, and information theory.</li>
            <li>Because continuous systems can be hard to solve, we often discretize them and use linear algebra to study them more easily.</li>
            <li>Von Neumann entropy of graphs applies these concepts to networks, helping us understand their structure and complexity.</li>
          </ul>
        </div>
      </section>
    </section>
  </main>

  <footer>
    <p>Site built by Regan Williams.</p>
  </footer>
</body>
</html>
